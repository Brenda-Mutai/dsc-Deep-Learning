{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgtpGH1XsplI"
      },
      "source": [
        "# Practice Notebook: Basics of Deep Learning and Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT7EbxRqsrwP"
      },
      "source": [
        "## Importing Pre-requisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hh1tDQE01Y6P"
      },
      "outputs": [],
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set dataframe column width as max\n",
        "# ---\n",
        "#\n",
        "pd.set_option('display.max.columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Show visualisation in the notebook\n",
        "# ---\n",
        "#\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbO22v-2s9C1"
      },
      "source": [
        "## Example: Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iABEt0jvs4ny"
      },
      "outputs": [],
      "source": [
        "## Example 1\n",
        "# ---\n",
        "# Create a classification model using neural networks that will make\n",
        "# a prediction on whether a person survived the titanic disaster.\n",
        "# ---\n",
        "# Train Dataset = https://bit.ly/31azYjb\n",
        "# Test Dataset = https://bit.ly/2XmmAYe\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcyeAslXt11E"
      },
      "source": [
        "### Step 1: Data Importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CFF31bfeuIOI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Class</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>821</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>8.6625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>15.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>75.2500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Survived  Class  Sex        Age     Fare\n",
              "821         1      3    1  27.000000   8.6625\n",
              "241         1      3    0  29.699118  15.5000\n",
              "366         1      1    0  60.000000  75.2500"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading and previewing the train dataset\n",
        "# ---\n",
        "#\n",
        "df = pd.read_csv('https://bit.ly/3d1Te88')\n",
        "df.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq52sCL4t7BI"
      },
      "source": [
        "### Step 2: Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zu8rl3KnH5xg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1], dtype=int64)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finding unique value for target variable\n",
        "df.Survived.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CsacnWa3uIqT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (891, 5)\n"
          ]
        }
      ],
      "source": [
        "# checking the datasets' shape\n",
        "print(\"Dataset shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "J7bSTlQJ2ep1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Survived      int64\n",
              "Class         int64\n",
              "Sex           int64\n",
              "Age         float64\n",
              "Fare        float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking data types of Train\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKDL-nmut98Z"
      },
      "source": [
        "### Step 3: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RDeueSB02pCX"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Survived    0\n",
              "Class       0\n",
              "Sex         0\n",
              "Age         0\n",
              "Fare        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checking for missing data in Train\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3Sw163YePaJY"
      },
      "outputs": [],
      "source": [
        "# Selecting our features\n",
        "# ---\n",
        "# The method we will use here will be to create a list containing\n",
        "# all column names and to remove our target variable name then\n",
        "# selecting the features with the feature names in list.\n",
        "# ---\n",
        "#\n",
        "properties = list(df.columns.values)\n",
        "properties.remove('Survived')\n",
        "X = df[properties]\n",
        "\n",
        "# Selecting our target variable\n",
        "# ---\n",
        "#\n",
        "y = df['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_zC-jvw4V4mF"
      },
      "outputs": [],
      "source": [
        "# Splitting our dataset\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pExozwHouAKA"
      },
      "source": [
        "### Step 4: Data Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PV0KUr7-Wjb"
      },
      "source": [
        "##### Creating Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imI39pwM-7ct"
      },
      "source": [
        "We will create a base model and compare its performance with our Artificial Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iLzgHbCtuJiF"
      },
      "outputs": [],
      "source": [
        "# For our base model, we will use the Random Forest Classifier\n",
        "# ---\n",
        "#\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Creating our base model instance\n",
        "# ---\n",
        "#\n",
        "random_forest_classifier = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Fitting our base model\n",
        "# ---\n",
        "#\n",
        "random_forest_classifier = random_forest_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Performing our prediction with the base model\n",
        "# ---\n",
        "#\n",
        "y_prediction = random_forest_classifier.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3jNq0htPhlRM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier 0.8097014925373134\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Random Forest Classifier\", accuracy_score(y_prediction, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwTGVmItkHsA"
      },
      "source": [
        "##### Creating our Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Lhqr4b0gIDXo"
      },
      "outputs": [],
      "source": [
        "# We first import the keras library which will help us build an Artificial Neural Network\n",
        "# ---\n",
        "# Artificial Neural Networks in Keras are defined as a sequence\n",
        "# of layers which would be input, hidden and output-layers.\n",
        "# Keras takes a group of sequential layers and stacks them together into a single model.\n",
        "# We also add dropout dropout regularization functions to the input and\n",
        "# hidden layers in order to prevent overfitting.\n",
        "# ---\n",
        "#\n",
        "import keras\n",
        "from keras.models import Sequential     # Used to initialize the Artificial Neural Network\n",
        "from keras.layers import Dense          # Used to build the hidden Layers\n",
        "from keras.layers import Dropout        # Used to prevent overfitting\n",
        "\n",
        "\n",
        "# We start by creating an instance of Artificial Neural Network as shown\n",
        "# ---\n",
        "# Our classifier will return is an integer value, 0 or 1.\n",
        "# ---\n",
        "#\n",
        "classifier = Sequential()\n",
        "\n",
        "# Then adding the input layer and the first hidden layer with dropout function.\n",
        "# The input layer would be the first layer of our Artificial Neural Network.\n",
        "# ---\n",
        "# ->  units = 100         : We specify the no. of units (neurons) our connected layer\n",
        "#                           (the hidden layer attached) is going to have.\n",
        "#                           Normally, you'd have to try different values as your no. of neurons\n",
        "#                           per layer through trial and error.\n",
        "# ->  input_dim = 4       : We make use of input_dim to pass the dimensions of the input data to the Dense layer.\n",
        "#                           This would be the no. of features in our dataset.\n",
        "# ->  activation = 'relu' : Within our hidden layers we use the relu function as it yields a satisfactory result most of the time.\n",
        "#                           However, we can also experiment with other activation functions.\n",
        "# Lastly, we add a dropout regularization function that will prevent our ANN from overfitting.\n",
        "# - We should always use a dropout rate between 20% and 50%.\n",
        "#   In our case will dropped 30% of the input data to avoid overfitting.\n",
        "#   The seed is set to 2 in order to get reproducible results.\n",
        "#   If we don't specify this each model's outcome would be different.\n",
        "# ---\n",
        "#\n",
        "classifier.add(Dense(units = 100, input_dim = 4, activation = 'relu'))\n",
        "classifier.add(Dropout(0.3, seed = 2))\n",
        "\n",
        "# Adding a second hidden layer\n",
        "# ---\n",
        "# The second layer is similar, we dont need to specify input dimension\n",
        "# as we have defined the model to be sequential so keras will automatically\n",
        "# consider input dimension to be same as the output of last layer i.e 4.\n",
        "# ---\n",
        "#\n",
        "classifier.add(Dense(units = 100, activation = 'relu'))\n",
        "classifier.add(Dropout(0.3, seed = 2))\n",
        "\n",
        "# Adding an output layer\n",
        "# ---\n",
        "# We set units = 1, because for our output, our ANN to return a single integer value, either 0 or 1.\n",
        "# We also use the sigmoid function which maps the values between 0 and 1.\n",
        "# ---\n",
        "#\n",
        "classifier.add(Dense(units = 1, activation = \"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FUb9iGDZIH4Y"
      },
      "outputs": [],
      "source": [
        "# Finally Compile our ANN\n",
        "# ---\n",
        "# By compiling, we are simply configuring the model for training\n",
        "# ---\n",
        "# optimizer = 'adam'  :          The optimizer controls the learning rate throughout training,\n",
        "#                                i.e. how fast the optimal weights for the model are calculated.\n",
        "#                                A smaller learning rate would lead to more accurate weights (up to a certain point),\n",
        "#                                but the time it takes to compute the weights will be longer.\n",
        "#                                'adam' is generally a good optimizer to use for many cases.\n",
        "# loss = 'binary_crossentropy':  This defines how we get closer to our loss.\n",
        "#                                In our case, since our output is binary, we use ‘binary_crossentropy’.\n",
        "#                                For multi-class classification we can use 'categorical_crossentropy; as our loss.\n",
        "#                                This would evaluate how well our ANN models the given data\n",
        "# Lastly, we choose accuracy as our evaluation metric.\n",
        "# ---\n",
        "#\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "E-R2dBH4IQd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "20/20 [==============================] - 1s 3ms/step - loss: 2.0234 - accuracy: 0.5795\n",
            "Epoch 2/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.7109 - accuracy: 0.6132\n",
            "Epoch 3/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.5831 - accuracy: 0.5923\n",
            "Epoch 4/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 1.3357 - accuracy: 0.5827\n",
            "Epoch 5/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.2112 - accuracy: 0.5811\n",
            "Epoch 6/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 1.0786 - accuracy: 0.6228\n",
            "Epoch 7/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.9729 - accuracy: 0.6083\n",
            "Epoch 8/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.8965 - accuracy: 0.6100\n",
            "Epoch 9/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.9049 - accuracy: 0.6421\n",
            "Epoch 10/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.8304 - accuracy: 0.6228\n",
            "Epoch 11/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7720 - accuracy: 0.6661\n",
            "Epoch 12/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.8459 - accuracy: 0.6292\n",
            "Epoch 13/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7642 - accuracy: 0.6276\n",
            "Epoch 14/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.7307 - accuracy: 0.6100\n",
            "Epoch 15/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7529 - accuracy: 0.6421\n",
            "Epoch 16/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7125 - accuracy: 0.6677\n",
            "Epoch 17/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7321 - accuracy: 0.6421\n",
            "Epoch 18/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.7478 - accuracy: 0.6292\n",
            "Epoch 19/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.6533\n",
            "Epoch 20/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.6469\n",
            "Epoch 21/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.6453\n",
            "Epoch 22/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.6469\n",
            "Epoch 23/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6559 - accuracy: 0.6565\n",
            "Epoch 24/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.6533\n",
            "Epoch 25/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.6693\n",
            "Epoch 26/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6629\n",
            "Epoch 27/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6392 - accuracy: 0.6726\n",
            "Epoch 28/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.6453\n",
            "Epoch 29/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6485\n",
            "Epoch 30/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.6501\n",
            "Epoch 31/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6661\n",
            "Epoch 32/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6557 - accuracy: 0.6469\n",
            "Epoch 33/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6380 - accuracy: 0.6469\n",
            "Epoch 34/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.6613\n",
            "Epoch 35/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.6613\n",
            "Epoch 36/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6162 - accuracy: 0.6565\n",
            "Epoch 37/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.6822\n",
            "Epoch 38/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6041 - accuracy: 0.6661\n",
            "Epoch 39/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6154 - accuracy: 0.6581\n",
            "Epoch 40/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6453\n",
            "Epoch 41/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6192 - accuracy: 0.6485\n",
            "Epoch 42/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.6645\n",
            "Epoch 43/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.6597\n",
            "Epoch 44/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.6693\n",
            "Epoch 45/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.6565\n",
            "Epoch 46/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6597\n",
            "Epoch 47/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.6581\n",
            "Epoch 48/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6790\n",
            "Epoch 49/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5798 - accuracy: 0.6742\n",
            "Epoch 50/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.6758\n",
            "Epoch 51/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.6629\n",
            "Epoch 52/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5883 - accuracy: 0.6469\n",
            "Epoch 53/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5890 - accuracy: 0.6677\n",
            "Epoch 54/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.6774\n",
            "Epoch 55/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6790\n",
            "Epoch 56/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6677\n",
            "Epoch 57/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6565\n",
            "Epoch 58/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5878 - accuracy: 0.6661\n",
            "Epoch 59/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5746 - accuracy: 0.6870\n",
            "Epoch 60/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.6661\n",
            "Epoch 61/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5755 - accuracy: 0.6726\n",
            "Epoch 62/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.6581\n",
            "Epoch 63/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5928 - accuracy: 0.6758\n",
            "Epoch 64/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5835 - accuracy: 0.6838\n",
            "Epoch 65/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.6645\n",
            "Epoch 66/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.6934\n",
            "Epoch 67/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6854\n",
            "Epoch 68/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.6870\n",
            "Epoch 69/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.6758\n",
            "Epoch 70/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5583 - accuracy: 0.6854\n",
            "Epoch 71/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5692 - accuracy: 0.6982\n",
            "Epoch 72/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.6854\n",
            "Epoch 73/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.6790\n",
            "Epoch 74/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.6886\n",
            "Epoch 75/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5709 - accuracy: 0.6790\n",
            "Epoch 76/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7223\n",
            "Epoch 77/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.6998\n",
            "Epoch 78/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.7030\n",
            "Epoch 79/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5668 - accuracy: 0.7095\n",
            "Epoch 80/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7175\n",
            "Epoch 81/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5555 - accuracy: 0.7047\n",
            "Epoch 82/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7287\n",
            "Epoch 83/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7175\n",
            "Epoch 84/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7271\n",
            "Epoch 85/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5490 - accuracy: 0.7335\n",
            "Epoch 86/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7287\n",
            "Epoch 87/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.7047\n",
            "Epoch 88/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7271\n",
            "Epoch 89/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5450 - accuracy: 0.7416\n",
            "Epoch 90/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7255\n",
            "Epoch 91/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7303\n",
            "Epoch 92/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7496\n",
            "Epoch 93/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7271\n",
            "Epoch 94/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7384\n",
            "Epoch 95/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5563 - accuracy: 0.7223\n",
            "Epoch 96/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7335\n",
            "Epoch 97/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7448\n",
            "Epoch 98/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7400\n",
            "Epoch 99/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7496\n",
            "Epoch 100/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7448\n",
            "Epoch 101/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5298 - accuracy: 0.7576\n",
            "Epoch 102/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7544\n",
            "Epoch 103/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7335\n",
            "Epoch 104/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7448\n",
            "Epoch 105/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7464\n",
            "Epoch 106/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7496\n",
            "Epoch 107/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.7352\n",
            "Epoch 108/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5354 - accuracy: 0.7416\n",
            "Epoch 109/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7448\n",
            "Epoch 110/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7608\n",
            "Epoch 111/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7368\n",
            "Epoch 112/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7624\n",
            "Epoch 113/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5360 - accuracy: 0.7464\n",
            "Epoch 114/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7624\n",
            "Epoch 115/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5301 - accuracy: 0.7608\n",
            "Epoch 116/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5390 - accuracy: 0.7512\n",
            "Epoch 117/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.7368\n",
            "Epoch 118/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7640\n",
            "Epoch 119/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7624\n",
            "Epoch 120/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7592\n",
            "Epoch 121/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7592\n",
            "Epoch 122/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5094 - accuracy: 0.7721\n",
            "Epoch 123/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7657\n",
            "Epoch 124/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7592\n",
            "Epoch 125/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.7592\n",
            "Epoch 126/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.7657\n",
            "Epoch 127/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.7544\n",
            "Epoch 128/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5228 - accuracy: 0.7496\n",
            "Epoch 129/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7608\n",
            "Epoch 130/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7624\n",
            "Epoch 131/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4961 - accuracy: 0.7769\n",
            "Epoch 132/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7801\n",
            "Epoch 133/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7673\n",
            "Epoch 134/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7801\n",
            "Epoch 135/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7833\n",
            "Epoch 136/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7592\n",
            "Epoch 137/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.7689\n",
            "Epoch 138/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7657\n",
            "Epoch 139/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7737\n",
            "Epoch 140/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7592\n",
            "Epoch 141/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7689\n",
            "Epoch 142/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7721\n",
            "Epoch 143/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5176 - accuracy: 0.7592\n",
            "Epoch 144/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7817\n",
            "Epoch 145/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7929\n",
            "Epoch 146/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7785\n",
            "Epoch 147/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7753\n",
            "Epoch 148/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7657\n",
            "Epoch 149/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7849\n",
            "Epoch 150/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4919 - accuracy: 0.7801\n",
            "Epoch 151/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7753\n",
            "Epoch 152/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7785\n",
            "Epoch 153/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4979 - accuracy: 0.7849\n",
            "Epoch 154/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7753\n",
            "Epoch 155/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4914 - accuracy: 0.7817\n",
            "Epoch 156/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7673\n",
            "Epoch 157/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7737\n",
            "Epoch 158/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.7785\n",
            "Epoch 159/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7881\n",
            "Epoch 160/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7785\n",
            "Epoch 161/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7865\n",
            "Epoch 162/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7705\n",
            "Epoch 163/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.8010\n",
            "Epoch 164/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5096 - accuracy: 0.7624\n",
            "Epoch 165/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7769\n",
            "Epoch 166/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7833\n",
            "Epoch 167/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.5081 - accuracy: 0.7608\n",
            "Epoch 168/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7721\n",
            "Epoch 169/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7913\n",
            "Epoch 170/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4879 - accuracy: 0.7833\n",
            "Epoch 171/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7817\n",
            "Epoch 172/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7817\n",
            "Epoch 173/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7849\n",
            "Epoch 174/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7817\n",
            "Epoch 175/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7881\n",
            "Epoch 176/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7881\n",
            "Epoch 177/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7785\n",
            "Epoch 178/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7994\n",
            "Epoch 179/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7865\n",
            "Epoch 180/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7897\n",
            "Epoch 181/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7897\n",
            "Epoch 182/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7785\n",
            "Epoch 183/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.7801\n",
            "Epoch 184/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7881\n",
            "Epoch 185/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7865\n",
            "Epoch 186/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7753\n",
            "Epoch 187/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7849\n",
            "Epoch 188/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7689\n",
            "Epoch 189/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7753\n",
            "Epoch 190/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.7801\n",
            "Epoch 191/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7817\n",
            "Epoch 192/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7769\n",
            "Epoch 193/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7913\n",
            "Epoch 194/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7897\n",
            "Epoch 195/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7897\n",
            "Epoch 196/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7833\n",
            "Epoch 197/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7737\n",
            "Epoch 198/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7817\n",
            "Epoch 199/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.7913\n",
            "Epoch 200/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7881\n",
            "Epoch 201/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7801\n",
            "Epoch 202/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7929\n",
            "Epoch 203/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7769\n",
            "Epoch 204/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7881\n",
            "Epoch 205/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7897\n",
            "Epoch 206/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7897\n",
            "Epoch 207/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4793 - accuracy: 0.7945\n",
            "Epoch 208/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7881\n",
            "Epoch 209/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7961\n",
            "Epoch 210/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7801\n",
            "Epoch 211/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7881\n",
            "Epoch 212/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7913\n",
            "Epoch 213/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7833\n",
            "Epoch 214/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7881\n",
            "Epoch 215/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7897\n",
            "Epoch 216/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7913\n",
            "Epoch 217/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7769\n",
            "Epoch 218/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8042\n",
            "Epoch 219/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7817\n",
            "Epoch 220/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7961\n",
            "Epoch 221/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7994\n",
            "Epoch 222/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7978\n",
            "Epoch 223/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7913\n",
            "Epoch 224/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.8042\n",
            "Epoch 225/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7897\n",
            "Epoch 226/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7961\n",
            "Epoch 227/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7849\n",
            "Epoch 228/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4761 - accuracy: 0.7865\n",
            "Epoch 229/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7913\n",
            "Epoch 230/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7865\n",
            "Epoch 231/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7945\n",
            "Epoch 232/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7978\n",
            "Epoch 233/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7785\n",
            "Epoch 234/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7961\n",
            "Epoch 235/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7961\n",
            "Epoch 236/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7913\n",
            "Epoch 237/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.8026\n",
            "Epoch 238/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.8010\n",
            "Epoch 239/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7994\n",
            "Epoch 240/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7881\n",
            "Epoch 241/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7994\n",
            "Epoch 242/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7994\n",
            "Epoch 243/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7865\n",
            "Epoch 244/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7945\n",
            "Epoch 245/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7897\n",
            "Epoch 246/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7897\n",
            "Epoch 247/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7961\n",
            "Epoch 248/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.8106\n",
            "Epoch 249/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7961\n",
            "Epoch 250/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7865\n",
            "Epoch 251/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7849\n",
            "Epoch 252/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7961\n",
            "Epoch 253/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7929\n",
            "Epoch 254/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7897\n",
            "Epoch 255/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7961\n",
            "Epoch 256/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7961\n",
            "Epoch 257/300\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7978\n",
            "Epoch 258/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7929\n",
            "Epoch 259/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.7961\n",
            "Epoch 260/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.8026\n",
            "Epoch 261/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8058\n",
            "Epoch 262/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.8026\n",
            "Epoch 263/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7961\n",
            "Epoch 264/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.8010\n",
            "Epoch 265/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.8010\n",
            "Epoch 266/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7961\n",
            "Epoch 267/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8138\n",
            "Epoch 268/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7801\n",
            "Epoch 269/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7961\n",
            "Epoch 270/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8026\n",
            "Epoch 271/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8090\n",
            "Epoch 272/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8090\n",
            "Epoch 273/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7865\n",
            "Epoch 274/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7978\n",
            "Epoch 275/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7929\n",
            "Epoch 276/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.8042\n",
            "Epoch 277/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7978\n",
            "Epoch 278/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.8122\n",
            "Epoch 279/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.8026\n",
            "Epoch 280/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7961\n",
            "Epoch 281/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7849\n",
            "Epoch 282/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7994\n",
            "Epoch 283/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8026\n",
            "Epoch 284/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.8010\n",
            "Epoch 285/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8074\n",
            "Epoch 286/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7945\n",
            "Epoch 287/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.8122\n",
            "Epoch 288/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7978\n",
            "Epoch 289/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.7978\n",
            "Epoch 290/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.8090\n",
            "Epoch 291/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8138\n",
            "Epoch 292/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.8138\n",
            "Epoch 293/300\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7881\n",
            "Epoch 294/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.8138\n",
            "Epoch 295/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4449 - accuracy: 0.8154\n",
            "Epoch 296/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8170\n",
            "Epoch 297/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.8058\n",
            "Epoch 298/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8090\n",
            "Epoch 299/300\n",
            "20/20 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8170\n",
            "Epoch 300/300\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.8026\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1cf0c9a5ea0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training our model\n",
        "# ---\n",
        "# Lets now train our model using our dataset.\n",
        "# Here learning is an iterative process and we tell the model to\n",
        "# go through our training dataset to learn as much as it can from it\n",
        "# ---\n",
        "# Training occurs over epochs and each epoch is split into batches.\n",
        "# - Epoch: One pass through all of the rows in the training dataset.\n",
        "# - Batch: One or more samples considered by the model within an epoch before weights are updated.\n",
        "#          The higher the batch size, the more memory space we'll need.\n",
        "# These configurations can be chosen experimentally by trial and error.\n",
        "# We want to train the model enough so that it learns a good (or good enough)\n",
        "# mapping of rows of input data to the output classification.\n",
        "# The model will always have some error, but the amount of error will level out\n",
        "# after some point for a given model configuration.\n",
        "# This point would be called as the point of model convergence.\n",
        "# ---\n",
        "# NB: We are using y_train set that underwent one hot encoding.\n",
        "# ---\n",
        "#\n",
        "classifier.fit(X_train, y_train, epochs = 300, batch_size = 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EbZwVLafQGvX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8134\n",
            "ANN Accuracy: 0.8134328126907349\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "# ---\n",
        "# We then evaluate our model for test set by checking the accuracy\n",
        "# ---\n",
        "# We can improve our model by:\n",
        "# 1. Optimizing the epochs.\n",
        "# 2. Optimizing the number of layers.\n",
        "# 3. Optimizing the number of nodes per layer.\n",
        "# ---\n",
        "#\n",
        "loss, accuracy = classifier.evaluate(X_test, y_test)\n",
        "print('ANN Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffP-HhLxuBi1"
      },
      "source": [
        "### Step 5: Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UkupyOl_uKFI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 127ms/step\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Question\n",
        "# ---\n",
        "# Say we wanted to determine whether a 40 year woman in Class 4 and Paid 30\n",
        "# survived the titanic we can make this prediction by\"\n",
        "# ---\n",
        "#\n",
        "new_value = np.array([[4, 0, 40, 30]])\n",
        "\n",
        "# Making our prediction\n",
        "# ---\n",
        "# We use the predict() method to get the predicted probabilities for each class.\n",
        "#\n",
        "predicted_probabilities = classifier.predict(new_value)\n",
        "\n",
        "# We use np.argmax() to find the index of the class with the highest probability, which is essentially the predicted class.\n",
        "# This should give you the desired output indicating whether the woman survived or not.\n",
        "# ---\n",
        "#\n",
        "predicted_class = np.argmax(predicted_probabilities)\n",
        "print(predicted_class)\n",
        "\n",
        "# The output would be 0 which, would mean the woman did not survive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTjlaLg4AsIi"
      },
      "source": [
        "## Example: Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "asgqGe8jAsIu"
      },
      "outputs": [],
      "source": [
        "## Example 1\n",
        "# ---\n",
        "# Create a regression model using artificial neural networks\n",
        "# to predict the weight of fish given the following dataset.\n",
        "# ---\n",
        "# Dataset = http://bit.ly/MRFishDataset\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYZoVkgwAsI4"
      },
      "source": [
        "### Step 1: Data Importation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TF16YkOKAsI5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>Pike</td>\n",
              "      <td>770.0</td>\n",
              "      <td>44.8</td>\n",
              "      <td>48.0</td>\n",
              "      <td>51.2</td>\n",
              "      <td>7.6800</td>\n",
              "      <td>5.3760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Bream</td>\n",
              "      <td>680.0</td>\n",
              "      <td>31.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>40.6</td>\n",
              "      <td>15.4686</td>\n",
              "      <td>6.1306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>Pike</td>\n",
              "      <td>456.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>42.5</td>\n",
              "      <td>45.5</td>\n",
              "      <td>7.2800</td>\n",
              "      <td>4.3225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Species  Weight  Length1  Length2  Length3   Height   Width\n",
              "139    Pike   770.0     44.8     48.0     51.2   7.6800  5.3760\n",
              "23    Bream   680.0     31.8     35.0     40.6  15.4686  6.1306\n",
              "134    Pike   456.0     40.0     42.5     45.5   7.2800  4.3225"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading and previewing the train dataset\n",
        "# ---\n",
        "#\n",
        "fish_df = pd.read_csv('http://bit.ly/MRFishDataset')\n",
        "fish_df.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zfDjd4HAsJT"
      },
      "source": [
        "### Step 2: Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qlk-BoSCFw44"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>398.326415</td>\n",
              "      <td>26.247170</td>\n",
              "      <td>28.415723</td>\n",
              "      <td>31.227044</td>\n",
              "      <td>8.970994</td>\n",
              "      <td>4.417486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>357.978317</td>\n",
              "      <td>9.996441</td>\n",
              "      <td>10.716328</td>\n",
              "      <td>11.610246</td>\n",
              "      <td>4.286208</td>\n",
              "      <td>1.685804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>1.728400</td>\n",
              "      <td>1.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>120.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.150000</td>\n",
              "      <td>5.944800</td>\n",
              "      <td>3.385650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>273.000000</td>\n",
              "      <td>25.200000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>29.400000</td>\n",
              "      <td>7.786000</td>\n",
              "      <td>4.248500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>650.000000</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>35.500000</td>\n",
              "      <td>39.650000</td>\n",
              "      <td>12.365900</td>\n",
              "      <td>5.584500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1650.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>63.400000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>18.957000</td>\n",
              "      <td>8.142000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Weight     Length1     Length2     Length3      Height       Width\n",
              "count   159.000000  159.000000  159.000000  159.000000  159.000000  159.000000\n",
              "mean    398.326415   26.247170   28.415723   31.227044    8.970994    4.417486\n",
              "std     357.978317    9.996441   10.716328   11.610246    4.286208    1.685804\n",
              "min       0.000000    7.500000    8.400000    8.800000    1.728400    1.047600\n",
              "25%     120.000000   19.050000   21.000000   23.150000    5.944800    3.385650\n",
              "50%     273.000000   25.200000   27.300000   29.400000    7.786000    4.248500\n",
              "75%     650.000000   32.700000   35.500000   39.650000   12.365900    5.584500\n",
              "max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Previewing the statistical summary of our dataset\n",
        "#\n",
        "fish_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX5nUdhGGIVD"
      },
      "outputs": [],
      "source": [
        "# Performing Exploratory Analysis\n",
        "# ---\n",
        "# This time we will plot a correlation matrix, to determine the relationships between the different variables.\n",
        "# This matrix will give us a sense of how well the variables are correlated. By this we mean, whether an\n",
        "# increase or decrease in variable affects the other variable.\n",
        "# To break this down further, the matrix will provide us with values between -1 and 1. If the value between\n",
        "# two variables is closer to 1 i.e. > 0.5, then it means the variables are strongly correlated, have a positive linear\n",
        "# relationship and it also means that as one value increases the other increases.\n",
        "# On the other hand, of the value is less than -0.5, it would mean that the variables are strongly correlated but\n",
        "# have a negative linear relationship.\n",
        "# If the value is 0 or < -0.5 or < 0.5 it means that the variables don't have any relationship with each other.\n",
        "# ---\n",
        "# This type of visualisation can help us examine an assumption of linear regression;\n",
        "# relationship of predicor variables with the response variable.\n",
        "# ---\n",
        "#\n",
        "corrMatrix = fish_df.corr()\n",
        "corrMatrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHfFeq9cGIVF"
      },
      "outputs": [],
      "source": [
        "# We can plot a visualisation of the matrix for better clarity\n",
        "# ---\n",
        "#\n",
        "import seaborn as sns\n",
        "\n",
        "# We define how big we want our visualisation\n",
        "#\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Creating our visualisation\n",
        "#\n",
        "sns.heatmap(corrMatrix, annot = True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4OF9HnrAsJn"
      },
      "source": [
        "### Step 3: Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q9ipuxEGE32"
      },
      "outputs": [],
      "source": [
        "# Selecting our feature and response variables\n",
        "# ---\n",
        "#\n",
        "X = fish_df[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
        "y = fish_df['Weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-ytfcVLAsJ-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Performing our split\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JwRbFhZAsKH"
      },
      "source": [
        "### Step 4: Data Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_Ytd4guAsKI"
      },
      "source": [
        "#### Creating the Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5ob19JIAsKJ"
      },
      "source": [
        "We will create a base model and compare its performance with our Artificial Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3NB25BVAsKL"
      },
      "outputs": [],
      "source": [
        "# For our base model, we will use the Random Forest Classifier\n",
        "# ---\n",
        "#\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Creating instances of our models\n",
        "# ---\n",
        "#\n",
        "decision_tree_regressor = DecisionTreeRegressor(random_state=0)\n",
        "\n",
        "# Training our machine learning algorithms\n",
        "# ---\n",
        "#\n",
        "decision_tree_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "# ---\n",
        "#\n",
        "decision_tree_pred = decision_tree_regressor.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQzlVpprAsKV"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "print('Decision Tree: Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, decision_tree_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIsPvb1cAsK6"
      },
      "source": [
        "#### Creating our Artificial Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chNAzqK9AsK7"
      },
      "outputs": [],
      "source": [
        "# Importing our library and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "# Instantiating our ANN regressor\n",
        "regressor = Sequential()\n",
        "\n",
        "# Adding input layer\n",
        "regressor.add(Dense(units = 10, input_dim = 5, activation = 'relu'))\n",
        "regressor.add(Dropout(0.3, seed = 2))\n",
        "\n",
        "# Adding a second hidden layer\n",
        "regressor.add(Dense(units = 10, activation = 'relu'))\n",
        "regressor.add(Dropout(0.3, seed = 2))\n",
        "\n",
        "# Adding an output layer\n",
        "# ---\n",
        "# Our network will end with a single unit 1, and doesn’t include an activation.\n",
        "# This would be the case for regression, where we are trying to predict a single continuous value.\n",
        "# ---\n",
        "regressor.add(Dense(units = 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827UoOpjAsK_"
      },
      "outputs": [],
      "source": [
        "# Finally Compiling our ANN\n",
        "# ---\n",
        "# We use the rsmprop as our optimization algorithm\n",
        "# and mse as the loss function which is popular mse as the loss function.\n",
        "# We also use the Mean Absolute Error (MAE) as a metric.\n",
        "# ---\n",
        "#\n",
        "regressor.compile(optimizer = 'adam', loss = 'mse', metrics = ['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HWHqv69AsLD"
      },
      "outputs": [],
      "source": [
        "# Training our model\n",
        "# ---\n",
        "#\n",
        "regressor.fit(X_train, y_train, epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTgresTcAsLI"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation on Test Data\n",
        "# ---\n",
        "# We use the evaluate() function which will calculate the values\n",
        "# of the metrics we chose when we compiled the model.\n",
        "# ---\n",
        "# - MAE (Mean Absolute Error) quantifies how close predictions are to the eventual outcomes.\n",
        "# - MSE (Mean Squared Error) measures the average of the squares of the errors or deviations.\n",
        "#   The closer to 0, the better. For our case, we will also use the RMSE.\n",
        "# ---\n",
        "#\n",
        "mse_value, mae_value = regressor.evaluate(X_test, y_test)\n",
        "\n",
        "print('Mean squared error: ', mse_value)\n",
        "print('Mean absolute error: ', mae_value)\n",
        "print('Root Mean squared error: ', np.sqrt(mse_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNHhdwuQr1hs"
      },
      "source": [
        "From our MAE, the regressor on average predicted 240.39 above or below the actual values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ9r88PwhuSU"
      },
      "source": [
        "#### Explaining our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym5kfJ-2jFZ_"
      },
      "source": [
        "In a case where we need to explain what are the major components used by our model to perform its prediction, we can use the **SHAP** library. This allows us to create a summary of our features and its impact on the model output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1dN-3M9h8sr"
      },
      "outputs": [],
      "source": [
        "# Installing shap\n",
        "# ---\n",
        "#\n",
        "!pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cjdEp-nhxF1"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "shap.initjs()\n",
        "\n",
        "explainer = shap.KernelExplainer(regressor, X_train.values)\n",
        "shap_values = explainer.shap_values(X_test.values)\n",
        "\n",
        "# Plot summary_plot as barplot\n",
        "# ---\n",
        "#\n",
        "shap.summary_plot(shap_values, X_test, plot_type='bar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZH_gmmIkjJR"
      },
      "source": [
        "The summary plot shows the most important features and the magnitude of their impact on the model. We can observe that Length2 contributed the most during prediction followed by Length3, Length1, Height and Width."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B2OfF79AsLM"
      },
      "source": [
        "### Step 5: Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw3DH7GUAsLN"
      },
      "outputs": [],
      "source": [
        "# Making predictions\n",
        "# ---\n",
        "# We make predictions using our ANN by passing an array\n",
        "# of feature values for our new prediction.\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Question:\n",
        "# ---\n",
        "# Say we wanted to determine the weight of fish with the following dimensions:\n",
        "# 1. Length1: 30.9\n",
        "# 2. Length2: 33.5\n",
        "# 3. Length3: 38.6\n",
        "# 4. Height:  15.6330\n",
        "# 5. Width:   5.1338\n",
        "# ---\n",
        "#\n",
        "new_value = np.array([[30.9, 33.5, 38.6, 25.6330, 5.1338]])\n",
        "\n",
        "# Making our prediction\n",
        "# ---\n",
        "#\n",
        "print(regressor.predict(new_value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLisP_91s2mM"
      },
      "source": [
        "## <font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDKOL1yjs1_g"
      },
      "outputs": [],
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Create an artificial neural networks classification model that\n",
        "# predicts insurance costs given the following dataset.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/30GtDfO\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgc3gbIAsjS9"
      },
      "outputs": [],
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Build a neural network to predict insurance costs given the following dataset.\n",
        "# ---\n",
        "# Dataset url = https://bit.ly/InsuranceDS\n",
        "# ---\n",
        "# YOUR CODE GOES BELOW\n",
        "#"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "BT7EbxRqsrwP",
        "DcyeAslXt11E",
        "aq52sCL4t7BI",
        "nKDL-nmut98Z",
        "pExozwHouAKA",
        "4PV0KUr7-Wjb",
        "CwTGVmItkHsA",
        "ffP-HhLxuBi1",
        "ZTjlaLg4AsIi",
        "YYZoVkgwAsI4",
        "2zfDjd4HAsJT",
        "R4OF9HnrAsJn",
        "6JwRbFhZAsKH",
        "o_Ytd4guAsKI",
        "JIsPvb1cAsK6",
        "nJ9r88PwhuSU",
        "_B2OfF79AsLM",
        "sLisP_91s2mM"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
